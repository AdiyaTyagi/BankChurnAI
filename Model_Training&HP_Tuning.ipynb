{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d566c663-2505-4058-8c9b-529a50baf815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-11 13:36:48,756] A new study created in memory with name: no-name-b2ea6e8e-3e23-4d94-b6e2-23f912efc84d\n",
      "[I 2025-04-11 13:36:49,258] Trial 0 finished with value: 0.33082894416924025 and parameters: {'C': 9.80412504519501}. Best is trial 0 with value: 0.33082894416924025.\n",
      "[I 2025-04-11 13:36:49,375] Trial 1 finished with value: 0.33082894416924025 and parameters: {'C': 8.950961476107652}. Best is trial 0 with value: 0.33082894416924025.\n",
      "[I 2025-04-11 13:36:49,476] Trial 2 finished with value: 0.33088896494566283 and parameters: {'C': 1.5384180062565578}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:49,586] Trial 3 finished with value: 0.33082894416924025 and parameters: {'C': 5.836099872911405}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:49,707] Trial 4 finished with value: 0.33082894416924025 and parameters: {'C': 5.6463264384735945}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:49,812] Trial 5 finished with value: 0.33088896494566283 and parameters: {'C': 1.601321888867792}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:49,917] Trial 6 finished with value: 0.33082894416924025 and parameters: {'C': 7.8218636167500195}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,019] Trial 7 finished with value: 0.33082894416924025 and parameters: {'C': 4.870697131690027}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,137] Trial 8 finished with value: 0.33082894416924025 and parameters: {'C': 8.591542228826901}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,238] Trial 9 finished with value: 0.33082894416924025 and parameters: {'C': 5.597931100929614}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,414] Trial 10 finished with value: 0.3306532896670658 and parameters: {'C': 0.358440817190786}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,518] Trial 11 finished with value: 0.3306532896670658 and parameters: {'C': 0.6550106063691171}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,653] Trial 12 finished with value: 0.33082894416924025 and parameters: {'C': 2.568233743163523}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,773] Trial 13 finished with value: 0.33082894416924025 and parameters: {'C': 2.8700923976516246}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,876] Trial 14 finished with value: 0.33082894416924025 and parameters: {'C': 2.027805941866486}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:50,963] Trial 15 finished with value: 0.33082894416924025 and parameters: {'C': 3.5799702055486087}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:51,070] Trial 16 finished with value: 0.33088896494566283 and parameters: {'C': 1.5001208667544175}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:51,163] Trial 17 finished with value: 0.33082894416924025 and parameters: {'C': 3.9235405849462}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:51,263] Trial 18 finished with value: 0.3217621377013369 and parameters: {'C': 0.019464687262991553}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:51,350] Trial 19 finished with value: 0.33088896494566283 and parameters: {'C': 1.2798265662034018}. Best is trial 2 with value: 0.33088896494566283.\n",
      "[I 2025-04-11 13:36:51,406] A new study created in memory with name: no-name-b1507150-6ff0-48dc-b617-5413a301fc23\n",
      "[I 2025-04-11 13:36:51,680] Trial 0 finished with value: 0.49523980262744827 and parameters: {'max_depth': 9, 'min_samples_split': 13}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:52,015] Trial 1 finished with value: 0.48242832758500764 and parameters: {'max_depth': 17, 'min_samples_split': 2}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:52,323] Trial 2 finished with value: 0.49076887547059805 and parameters: {'max_depth': 12, 'min_samples_split': 11}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:52,635] Trial 3 finished with value: 0.4829647515884023 and parameters: {'max_depth': 14, 'min_samples_split': 5}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:52,731] Trial 4 finished with value: 0.34475494064826556 and parameters: {'max_depth': 3, 'min_samples_split': 13}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:53,051] Trial 5 finished with value: 0.48723202853261394 and parameters: {'max_depth': 14, 'min_samples_split': 2}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:53,351] Trial 6 finished with value: 0.4917609527949202 and parameters: {'max_depth': 12, 'min_samples_split': 4}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:53,719] Trial 7 finished with value: 0.47455642328348197 and parameters: {'max_depth': 18, 'min_samples_split': 4}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:54,075] Trial 8 finished with value: 0.4914854114447029 and parameters: {'max_depth': 13, 'min_samples_split': 13}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:54,444] Trial 9 finished with value: 0.4841791379295273 and parameters: {'max_depth': 19, 'min_samples_split': 13}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:54,683] Trial 10 finished with value: 0.48512519156938544 and parameters: {'max_depth': 7, 'min_samples_split': 19}. Best is trial 0 with value: 0.49523980262744827.\n",
      "[I 2025-04-11 13:36:54,942] Trial 11 finished with value: 0.49669575752932343 and parameters: {'max_depth': 8, 'min_samples_split': 8}. Best is trial 11 with value: 0.49669575752932343.\n",
      "[I 2025-04-11 13:36:55,184] Trial 12 finished with value: 0.4842971999432811 and parameters: {'max_depth': 7, 'min_samples_split': 9}. Best is trial 11 with value: 0.49669575752932343.\n",
      "[I 2025-04-11 13:36:55,445] Trial 13 finished with value: 0.497612904348727 and parameters: {'max_depth': 8, 'min_samples_split': 18}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:55,590] Trial 14 finished with value: 0.34475494064826556 and parameters: {'max_depth': 3, 'min_samples_split': 20}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:55,887] Trial 15 finished with value: 0.49729042369986054 and parameters: {'max_depth': 9, 'min_samples_split': 16}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:56,066] Trial 16 finished with value: 0.4769302890007525 and parameters: {'max_depth': 5, 'min_samples_split': 17}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:56,390] Trial 17 finished with value: 0.4909853047198245 and parameters: {'max_depth': 10, 'min_samples_split': 17}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:56,655] Trial 18 finished with value: 0.4908091870522869 and parameters: {'max_depth': 10, 'min_samples_split': 16}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:57,001] Trial 19 finished with value: 0.48088528401543473 and parameters: {'max_depth': 16, 'min_samples_split': 15}. Best is trial 13 with value: 0.497612904348727.\n",
      "[I 2025-04-11 13:36:57,110] A new study created in memory with name: no-name-5cacd733-c022-4a5d-96cc-c3a74c11458f\n",
      "[I 2025-04-11 13:37:03,478] Trial 0 finished with value: 0.2029022589003404 and parameters: {'n_estimators': 230, 'max_depth': 5, 'min_samples_split': 11}. Best is trial 0 with value: 0.2029022589003404.\n",
      "[I 2025-04-11 13:37:17,226] Trial 1 finished with value: 0.48499583275647495 and parameters: {'n_estimators': 239, 'max_depth': 14, 'min_samples_split': 13}. Best is trial 1 with value: 0.48499583275647495.\n",
      "[I 2025-04-11 13:37:27,300] Trial 2 finished with value: 0.33579561367157423 and parameters: {'n_estimators': 292, 'max_depth': 7, 'min_samples_split': 5}. Best is trial 1 with value: 0.48499583275647495.\n",
      "[I 2025-04-11 13:37:38,730] Trial 3 finished with value: 0.4521862727268453 and parameters: {'n_estimators': 195, 'max_depth': 10, 'min_samples_split': 12}. Best is trial 1 with value: 0.48499583275647495.\n",
      "[I 2025-04-11 13:37:55,275] Trial 4 finished with value: 0.491851493817852 and parameters: {'n_estimators': 219, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 4 with value: 0.491851493817852.\n",
      "[I 2025-04-11 13:38:03,539] Trial 5 finished with value: 0.49533352449618384 and parameters: {'n_estimators': 116, 'max_depth': 18, 'min_samples_split': 18}. Best is trial 5 with value: 0.49533352449618384.\n",
      "[I 2025-04-11 13:38:23,209] Trial 6 finished with value: 0.4994722016108777 and parameters: {'n_estimators': 293, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 6 with value: 0.4994722016108777.\n",
      "[I 2025-04-11 13:38:35,431] Trial 7 finished with value: 0.3869583572186606 and parameters: {'n_estimators': 293, 'max_depth': 8, 'min_samples_split': 15}. Best is trial 6 with value: 0.4994722016108777.\n",
      "[I 2025-04-11 13:38:48,568] Trial 8 finished with value: 0.49856903147860904 and parameters: {'n_estimators': 201, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 6 with value: 0.4994722016108777.\n",
      "[I 2025-04-11 13:38:53,217] Trial 9 finished with value: 0.433151718849474 and parameters: {'n_estimators': 107, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 6 with value: 0.4994722016108777.\n",
      "[I 2025-04-11 13:39:03,374] Trial 10 finished with value: 0.49642653201438813 and parameters: {'n_estimators': 155, 'max_depth': 20, 'min_samples_split': 8}. Best is trial 6 with value: 0.4994722016108777.\n",
      "[I 2025-04-11 13:39:18,392] Trial 11 finished with value: 0.5004172397736049 and parameters: {'n_estimators': 256, 'max_depth': 17, 'min_samples_split': 7}. Best is trial 11 with value: 0.5004172397736049.\n",
      "[I 2025-04-11 13:39:35,129] Trial 12 finished with value: 0.4960428662152829 and parameters: {'n_estimators': 268, 'max_depth': 20, 'min_samples_split': 8}. Best is trial 11 with value: 0.5004172397736049.\n",
      "[I 2025-04-11 13:39:51,975] Trial 13 finished with value: 0.4956487136324528 and parameters: {'n_estimators': 263, 'max_depth': 16, 'min_samples_split': 7}. Best is trial 11 with value: 0.5004172397736049.\n",
      "[I 2025-04-11 13:40:05,932] Trial 14 finished with value: 0.4778283555633492 and parameters: {'n_estimators': 263, 'max_depth': 12, 'min_samples_split': 7}. Best is trial 11 with value: 0.5004172397736049.\n",
      "[I 2025-04-11 13:40:24,082] Trial 15 finished with value: 0.5005826550245143 and parameters: {'n_estimators': 290, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 15 with value: 0.5005826550245143.\n",
      "[I 2025-04-11 13:40:37,566] Trial 16 finished with value: 0.4793807416309848 and parameters: {'n_estimators': 255, 'max_depth': 12, 'min_samples_split': 2}. Best is trial 15 with value: 0.5005826550245143.\n",
      "[I 2025-04-11 13:40:48,570] Trial 17 finished with value: 0.49714951820135167 and parameters: {'n_estimators': 182, 'max_depth': 17, 'min_samples_split': 10}. Best is trial 15 with value: 0.5005826550245143.\n",
      "[I 2025-04-11 13:41:03,907] Trial 18 finished with value: 0.4893848847183624 and parameters: {'n_estimators': 275, 'max_depth': 14, 'min_samples_split': 2}. Best is trial 15 with value: 0.5005826550245143.\n",
      "[I 2025-04-11 13:41:17,602] Trial 19 finished with value: 0.49269750917057453 and parameters: {'n_estimators': 245, 'max_depth': 18, 'min_samples_split': 20}. Best is trial 15 with value: 0.5005826550245143.\n",
      "[I 2025-04-11 13:41:26,252] A new study created in memory with name: no-name-be255f4c-6c15-4321-9abe-c36f586db762\n",
      "[I 2025-04-11 13:43:25,254] Trial 0 finished with value: 0.0 and parameters: {'C': 1.42375483677139, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-11 13:45:17,590] Trial 1 finished with value: 0.0 and parameters: {'C': 1.209573499683432, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-11 13:48:15,337] Trial 2 finished with value: 0.0 and parameters: {'C': 2.72361424130646, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-11 13:49:25,168] Trial 3 finished with value: 0.0 and parameters: {'C': 0.31122638599537017, 'gamma': 'scale', 'kernel': 'linear'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-11 13:53:21,527] Trial 4 finished with value: 0.0 and parameters: {'C': 5.511049088724154, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-11 13:59:00,269] Trial 5 finished with value: 0.0 and parameters: {'C': 7.651208324946312, 'gamma': 'scale', 'kernel': 'linear'}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-11 14:01:15,446] Trial 6 finished with value: 0.41602001816377543 and parameters: {'C': 4.7957288378066, 'gamma': 'auto', 'kernel': 'rbf'}. Best is trial 6 with value: 0.41602001816377543.\n",
      "[I 2025-04-11 14:05:34,688] Trial 7 finished with value: 0.0 and parameters: {'C': 6.167029475849368, 'gamma': 'scale', 'kernel': 'linear'}. Best is trial 6 with value: 0.41602001816377543.\n",
      "[I 2025-04-11 14:10:05,319] Trial 8 finished with value: 0.0 and parameters: {'C': 6.703227303233305, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 6 with value: 0.41602001816377543.\n",
      "[I 2025-04-11 14:12:14,235] Trial 9 finished with value: 0.0 and parameters: {'C': 1.839707246798752, 'gamma': 'auto', 'kernel': 'linear'}. Best is trial 6 with value: 0.41602001816377543.\n",
      "[I 2025-04-11 14:14:27,624] Trial 10 finished with value: 0.40928093232635815 and parameters: {'C': 3.769492984041424, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 6 with value: 0.41602001816377543.\n",
      "[I 2025-04-11 14:16:41,185] Trial 11 finished with value: 0.40928093232635815 and parameters: {'C': 3.7659836358878236, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 6 with value: 0.41602001816377543.\n",
      "[I 2025-04-11 14:19:16,706] Trial 12 finished with value: 0.42648204743546864 and parameters: {'C': 9.736246489369588, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 12 with value: 0.42648204743546864.\n",
      "[I 2025-04-11 14:21:52,229] Trial 13 finished with value: 0.4267017080219175 and parameters: {'C': 9.85994047647926, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:24:26,481] Trial 14 finished with value: 0.4258011547006835 and parameters: {'C': 9.569226023238697, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:27:03,010] Trial 15 finished with value: 0.4264818206560654 and parameters: {'C': 9.650205578940128, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:29:32,021] Trial 16 finished with value: 0.42193342938678163 and parameters: {'C': 8.088202262298331, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:32:02,202] Trial 17 finished with value: 0.42104109892445524 and parameters: {'C': 8.53337858825004, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:34:35,699] Trial 18 finished with value: 0.4228527736907091 and parameters: {'C': 8.910260598557691, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:37:06,740] Trial 19 finished with value: 0.42198248263676225 and parameters: {'C': 7.26961211284467, 'gamma': 'scale', 'kernel': 'rbf'}. Best is trial 13 with value: 0.4267017080219175.\n",
      "[I 2025-04-11 14:39:53,486] A new study created in memory with name: no-name-bb0ff5f6-8e95-4c47-b19a-7bb5dba9b9f6\n",
      "[I 2025-04-11 14:39:54,391] Trial 0 finished with value: 0.536125406533261 and parameters: {'n_estimators': 266, 'learning_rate': 0.06332621212509473, 'max_depth': 7}. Best is trial 0 with value: 0.536125406533261.\n",
      "[I 2025-04-11 14:39:55,666] Trial 1 finished with value: 0.5334462742165398 and parameters: {'n_estimators': 230, 'learning_rate': 0.20848697831772484, 'max_depth': 10}. Best is trial 0 with value: 0.536125406533261.\n",
      "[I 2025-04-11 14:39:56,534] Trial 2 finished with value: 0.5195921536377691 and parameters: {'n_estimators': 241, 'learning_rate': 0.030291560241233945, 'max_depth': 7}. Best is trial 0 with value: 0.536125406533261.\n",
      "[I 2025-04-11 14:39:56,847] Trial 3 finished with value: 0.4994088588267846 and parameters: {'n_estimators': 191, 'learning_rate': 0.09350530420690506, 'max_depth': 3}. Best is trial 0 with value: 0.536125406533261.\n",
      "[I 2025-04-11 14:39:57,664] Trial 4 finished with value: 0.5400009007605431 and parameters: {'n_estimators': 200, 'learning_rate': 0.10173425262184135, 'max_depth': 8}. Best is trial 4 with value: 0.5400009007605431.\n",
      "[I 2025-04-11 14:39:58,753] Trial 5 finished with value: 0.5337151282280849 and parameters: {'n_estimators': 198, 'learning_rate': 0.03872014778493975, 'max_depth': 9}. Best is trial 4 with value: 0.5400009007605431.\n",
      "[I 2025-04-11 14:39:59,016] Trial 6 finished with value: 0.536905051617511 and parameters: {'n_estimators': 119, 'learning_rate': 0.29094807652445953, 'max_depth': 4}. Best is trial 4 with value: 0.5400009007605431.\n",
      "[I 2025-04-11 14:39:59,597] Trial 7 finished with value: 0.5328576903142145 and parameters: {'n_estimators': 101, 'learning_rate': 0.09995833492391344, 'max_depth': 9}. Best is trial 4 with value: 0.5400009007605431.\n",
      "[I 2025-04-11 14:40:01,020] Trial 8 finished with value: 0.5240753005843228 and parameters: {'n_estimators': 297, 'learning_rate': 0.016695596561297637, 'max_depth': 8}. Best is trial 4 with value: 0.5400009007605431.\n",
      "[I 2025-04-11 14:40:01,909] Trial 9 finished with value: 0.5328872934705878 and parameters: {'n_estimators': 119, 'learning_rate': 0.10636484165188693, 'max_depth': 9}. Best is trial 4 with value: 0.5400009007605431.\n",
      "[I 2025-04-11 14:40:02,444] Trial 10 finished with value: 0.5405299414046881 and parameters: {'n_estimators': 158, 'learning_rate': 0.19091038872078547, 'max_depth': 5}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:02,935] Trial 11 finished with value: 0.5345711248924867 and parameters: {'n_estimators': 151, 'learning_rate': 0.1805690349559193, 'max_depth': 5}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:03,445] Trial 12 finished with value: 0.5327751279024007 and parameters: {'n_estimators': 167, 'learning_rate': 0.23265135693614392, 'max_depth': 5}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:04,035] Trial 13 finished with value: 0.5361067033293113 and parameters: {'n_estimators': 161, 'learning_rate': 0.14984005399215278, 'max_depth': 6}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:04,831] Trial 14 finished with value: 0.5356184317272156 and parameters: {'n_estimators': 226, 'learning_rate': 0.1467294916949744, 'max_depth': 6}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:05,273] Trial 15 finished with value: 0.5223644836112471 and parameters: {'n_estimators': 190, 'learning_rate': 0.24790786535505333, 'max_depth': 3}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:05,739] Trial 16 finished with value: 0.5313830151974687 and parameters: {'n_estimators': 143, 'learning_rate': 0.17150249426619799, 'max_depth': 5}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:06,876] Trial 17 finished with value: 0.5280424531598001 and parameters: {'n_estimators': 213, 'learning_rate': 0.1263537769484473, 'max_depth': 8}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:07,318] Trial 18 finished with value: 0.5354438694316062 and parameters: {'n_estimators': 173, 'learning_rate': 0.19617737776589242, 'max_depth': 4}. Best is trial 10 with value: 0.5405299414046881.\n",
      "[I 2025-04-11 14:40:08,661] Trial 19 finished with value: 0.5388946428228438 and parameters: {'n_estimators': 264, 'learning_rate': 0.06327065654742747, 'max_depth': 8}. Best is trial 10 with value: 0.5405299414046881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Final Comparison Table =====\n",
      "                                   Model  Accuracy  Precision    Recall  \\\n",
      "0                       XGBoost (Optuna)  0.908327   0.663342  0.487626   \n",
      "1                         XGBoost (Base)  0.903461   0.630072  0.483960   \n",
      "2                 Random Forest (Optuna)  0.902355   0.648571  0.416132   \n",
      "3                   Random Forest (Base)  0.900254   0.637155  0.402383   \n",
      "4         Random Forest (RandomSearchCV)  0.900586   0.642433  0.396884   \n",
      "5                 Decision Tree (Optuna)  0.894725   0.593540  0.404216   \n",
      "6         Decision Tree (RandomSearchCV)  0.892071   0.573248  0.412466   \n",
      "7                   Decision Tree (Base)  0.873383   0.475543  0.481210   \n",
      "8                           SVM (Optuna)  0.896163   0.627090  0.343721   \n",
      "9                   SVM (RandomSearchCV)  0.896052   0.626043  0.343721   \n",
      "10                            SVM (Base)  0.895389   0.653277  0.283226   \n",
      "11              XGBoost (RandomSearchCV)  0.896384   0.696429  0.250229   \n",
      "12  Logistic Regression (RandomSearchCV)  0.889417   0.607565  0.235564   \n",
      "13            Logistic Regression (Base)  0.889307   0.606635  0.234647   \n",
      "14          Logistic Regression (Optuna)  0.889307   0.606635  0.234647   \n",
      "\n",
      "    F1 Score   ROC AUC  Training Time (s)  \n",
      "0   0.562071  0.932187           0.185031  \n",
      "1   0.547434  0.928659           1.452749  \n",
      "2   0.506979  0.925795           8.634448  \n",
      "3   0.493258  0.925499           3.621632  \n",
      "4   0.490652  0.924995           5.573339  \n",
      "5   0.480916  0.873157           0.098515  \n",
      "6   0.479744  0.838418           0.096025  \n",
      "7   0.478360  0.704199           0.184045  \n",
      "8   0.444050  0.866568         166.700194  \n",
      "9   0.443787  0.866689         207.343682  \n",
      "10  0.395141  0.856958          94.538903  \n",
      "11  0.368173  0.904386           0.600154  \n",
      "12  0.339498  0.872521           0.016003  \n",
      "13  0.338401  0.872526           0.048021  \n",
      "14  0.338401  0.872523           0.040999  \n"
     ]
    }
   ],
   "source": [
    "# model_comparison_full.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =======================\n",
    "# 1. Load and preprocess data\n",
    "# =======================\n",
    "df = pd.read_csv(\"Bank_Marketing.csv\")\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"TARGET\", axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =======================\n",
    "# 2. Model initialization\n",
    "# =======================\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# 3. Evaluate model\n",
    "# =======================\n",
    "def evaluate_model(name, model):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
    "    end = time.time()\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "        \"Training Time (s)\": end - start\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# =======================\n",
    "# 4. Base model evaluation\n",
    "# =======================\n",
    "for name, model in models.items():\n",
    "    results.append(evaluate_model(name + \" (Base)\", model))\n",
    "\n",
    "# =======================\n",
    "# 5. RandomizedSearchCV tuning\n",
    "# =======================\n",
    "tuning_params = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"penalty\": [\"l2\"]\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [3, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [5, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"gamma\": ['scale', 'auto'],\n",
    "        \"kernel\": [\"rbf\", \"linear\"]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    rsearch = RandomizedSearchCV(models[name], tuning_params[name], n_iter=10, cv=3, scoring=\"f1\", n_jobs=-1)\n",
    "    rsearch.fit(X_train, y_train)\n",
    "    results.append(evaluate_model(name + \" (RandomSearchCV)\", rsearch.best_estimator_))\n",
    "\n",
    "# =======================\n",
    "# 6. Optuna tuning\n",
    "# =======================\n",
    "def optuna_objective(trial, model_name):\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        model = LogisticRegression(C=trial.suggest_float(\"C\", 0.01, 10.0), penalty=\"l2\")\n",
    "    elif model_name == \"Decision Tree\":\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20))\n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 5, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20))\n",
    "    elif model_name == \"SVM\":\n",
    "        model = SVC(\n",
    "            C=trial.suggest_float(\"C\", 0.1, 10.0),\n",
    "            gamma=trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "            kernel=trial.suggest_categorical(\"kernel\", [\"rbf\", \"linear\"]),\n",
    "            probability=True)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring=\"f1\").mean()\n",
    "    return score\n",
    "\n",
    "for model_name in models:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: optuna_objective(trial, model_name), n_trials=20)\n",
    "    best_params = study.best_params\n",
    "    best_model = None\n",
    "\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        best_model = LogisticRegression(**best_params)\n",
    "    elif model_name == \"Decision Tree\":\n",
    "        best_model = DecisionTreeClassifier(**best_params)\n",
    "    elif model_name == \"Random Forest\":\n",
    "        best_model = RandomForestClassifier(**best_params)\n",
    "    elif model_name == \"SVM\":\n",
    "        best_model = SVC(**best_params, probability=True)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "    results.append(evaluate_model(model_name + \" (Optuna)\", best_model))\n",
    "\n",
    "# =======================\n",
    "# 7. Save & Show Results\n",
    "# =======================\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"results/model_comparison_all.csv\", index=False)\n",
    "print(\"\\n===== Final Comparison Table =====\")\n",
    "print(results_df.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653d01d-5bf7-48fb-b910-ec8f6dd07052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
